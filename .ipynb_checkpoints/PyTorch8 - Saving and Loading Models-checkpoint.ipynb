{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading Models\n",
    "Saving and Loading is important because you'll often want to load previously trained models to use in the making predictions or to continue training on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import helper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 233,
       "width": 233
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Deifne a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_date1', download=True, train=True, transform = transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_date1', download=True, train=True, transform = transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)\n",
    "\n",
    "image, label = next(iter(trainloader))\n",
    "helper.imshow(image[0,:]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define network architecture\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "        # Dropout module with 0.2 drop probability\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # make sure input tensor is flattened\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        # Now with dropout\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        \n",
    "        # Output so not dropout here\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10..  Training Loss: 0.601..  Test Loss: 0.429..  Test Accuracy: 0.845\n",
      "Epoch: 2/10..  Training Loss: 0.480..  Test Loss: 0.386..  Test Accuracy: 0.863\n",
      "Epoch: 3/10..  Training Loss: 0.449..  Test Loss: 0.377..  Test Accuracy: 0.863\n",
      "Epoch: 4/10..  Training Loss: 0.430..  Test Loss: 0.349..  Test Accuracy: 0.873\n",
      "Epoch: 5/10..  Training Loss: 0.414..  Test Loss: 0.355..  Test Accuracy: 0.865\n",
      "Epoch: 6/10..  Training Loss: 0.415..  Test Loss: 0.332..  Test Accuracy: 0.875\n",
      "Epoch: 7/10..  Training Loss: 0.402..  Test Loss: 0.316..  Test Accuracy: 0.885\n",
      "Epoch: 8/10..  Training Loss: 0.399..  Test Loss: 0.322..  Test Accuracy: 0.882\n",
      "Epoch: 9/10..  Training Loss: 0.393..  Test Loss: 0.336..  Test Accuracy: 0.879\n",
      "Epoch: 10/10..  Training Loss: 0.387..  Test Loss: 0.306..  Test Accuracy: 0.888\n"
     ]
    }
   ],
   "source": [
    "model = Classifier()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 10\n",
    "steps = 0\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        log_ps = model(images)\n",
    "        loss = criterion(log_ps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss +=loss.item()\n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        \n",
    "        # turn off gradients for validation, saves memory and computations\n",
    "        with torch.no_grad():\n",
    "            model.eval() # truns off the dropout\n",
    "            for images, labels in testloader:\n",
    "                log_ps = model(images)\n",
    "                test_loss += criterion(log_ps, labels)\n",
    "                \n",
    "                ps = torch.exp(log_ps)\n",
    "                top_p, top_class = ps.topk(1, dim=1)\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "                \n",
    "        model.train()\n",
    "        \n",
    "        train_losses.append(running_loss/len(trainloader))\n",
    "        test_losses.append(test_loss/len(testloader))\n",
    "        \n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our model: \n",
      "\n",
      " Classifier(\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.2)\n",
      ") \n",
      "\n",
      "The state dict keys: \n",
      "\n",
      " odict_keys(['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(\"our model: \\n\\n\", model, '\\n')\n",
    "print(\"The state dict keys: \\n\\n\", model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest thing to do is simply save the state dict with `torch.save`. For example, we can save it to a file `'checkpoint.pth'`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can load the state dict with `torch.load`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(state_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to load the state dict in to the network, you do `model.load_state_dict(state_dict)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "Seems pretty straightforwar, but as usual it's a bit more complicated. Loading the state dict works only if the model architecture is exactly the same as the checkpoint architecture. If I create a model with a different architecture, this fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
