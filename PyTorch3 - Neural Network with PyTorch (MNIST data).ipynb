{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural networks with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import helper\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),])\n",
    "\n",
    "#Download and load the training data\n",
    "trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform = transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, I created batch size of 64 on `trainloader` and `shuffle=True`. The batch size is the number of images we get in one iteration from the data loader and pass through the network, often called batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# NOTE: The shape of the images is [64,1,28,28] - 64 images per batch, 1 color channel, and 28x28 images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape) # Train loader is batch size of 64 (number of images)\n",
    "print(labels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x29f1a0bcbe0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[0].numpy().squeeze(), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple network using weight matrices and matrix multiplications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 784])\n"
     ]
    }
   ],
   "source": [
    "# Our images are 28x28 2D tensor, so we need to convert them into 1D vetors.\n",
    "# we convert images shape from (64,1,28,28) to shape of (64,784)\n",
    "# This process is called flattening, we flattened the 2D images into 1D vectors\n",
    "def activation(x):\n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n",
    "# Flatten the input images\n",
    "inputs = images.view(images.shape[0],-1) #Btach size, and -1 flatten rest of the dimensions \n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "# Create parameters\n",
    "w1 = torch.randn(784, 256)\n",
    "b1 = torch.randn(256)\n",
    "\n",
    "w2 = torch.randn(256, 10)\n",
    "b2 = torch.randn(10)\n",
    "\n",
    "h = activation(torch.mm(inputs,w1)+b1)\n",
    "out = torch.mm(h, w2)+b2\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000])\n"
     ]
    }
   ],
   "source": [
    "# Softmax function: to calculate the probability distribution of the images and its possible classes\n",
    "def softmax(x):\n",
    "    return torch.exp(x)/torch.sum(torch.exp(x), dim=1).view(-1,1)\n",
    "\n",
    "probabilities = softmax(out)\n",
    "\n",
    "# Does it have the right shape? should be (64,10)\n",
    "print(probabilities.shape)\n",
    "\n",
    "# Deas it sum to 1?\n",
    "print(probabilities.sum(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building networks with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch provides a module nn that makes networks much simpler\n",
    "# Same network same as above with 784 inputs, 256 hidden units, 10 output units and a softmax output\n",
    "from torch import nn\n",
    "\n",
    "class Network(nn.Module):                     # Network is subclass of nn.Module\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        \n",
    "        # Inputs to hidden layer linear transformation\n",
    "        # Size of the inputs for this linear operation is 784 and size of output is 256\n",
    "        self.hidden = nn.Linear(784, 256)     # creates the operation for linear transformation (nn.Linear()) is y = Wx+b\n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.output = nn.Linear(256, 10)      \n",
    "        \n",
    "        # Define sigmoid activation and softmax output\n",
    "        # just defining the functions, we use in forward method below\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        # Pass the input tensor through each of our operations\n",
    "        x = self.hidden(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.output(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative way to create the same Netowrk class and much cleaner\n",
    "import torch.nn.functional as F\n",
    "class Network2(nn.Module):                     # Network is subclass of nn.Module\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        \n",
    "        # Inputs to hidden layer linear transformation\n",
    "        # Size of the inputs for this linear operation is 784 and size of output is 256\n",
    "        self.hidden = nn.Linear(784, 256)     # creates the operation for linear transformation (nn.Linear()) is y = Wx+b\n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.output = nn.Linear(256, 10)      \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass the input tensor through each of our operations\n",
    "        # Hidden layer with sigmoid activation\n",
    "        x = F.sigmoid(self.hidden(x))\n",
    "        # output layer with softmax activation\n",
    "        x = F.softmax(self.output(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network2(\n",
       "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = Network2()\n",
    "model2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation Function:\n",
    "- Sigmoid\n",
    "- TanH\n",
    "- ReLU\n",
    "In practice, the ReLU function is used almost exclusively as the activation function for hidden layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End of the secton"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
